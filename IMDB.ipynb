{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivganev/imdb-movie-reviews/blob/main/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# IMDB Dataset of 50K Movie Reviews\n",
        "\n"
      ],
      "metadata": {
        "id": "nqwgDlDVEsCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this notebook, we perform a sentiment analysis on a Kaggle dataset of movie reviews. Here is the description from Kaggle:\n",
        "\n",
        "> *IMDB dataset having 50K movie reviews for natural language processing or Text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms.*\n",
        "\n",
        "\n",
        "Our approach features a recurrent neural network with a long short-term memory (LSTM) cell. Step-by-step:\n",
        "\n",
        "* Obtain the data from Kaggle.\n",
        "\n",
        "* Split the data into train and test set as indicated (25K each).\n",
        "\n",
        "* Preprocess the data by tokenizing words and forming a vocabulary.\n",
        "\n",
        "* Form the LSTM neural network model.  \n",
        "\n",
        "* Train the model using stochastic gradient descent. Due to GPU constraints, I was not able to train on the entire data set.\n",
        "\n",
        "* Evaluate the model on the test set.\n",
        "\n",
        "We begin with standard imports:"
      ],
      "metadata": {
        "id": "fb96xmD5hU5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PMTsjMFVehwY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Obtain the data from Kaggle\n",
        "\n",
        "The first step is to obtain the data from Kaggle. This notebook is intended to be run in Google CoLab, so the first step is to mount google drive:\n",
        "\n",
        "<!-- We follow the instructions on this [page](https://towardsdatascience.com/downloading-kaggle-datasets-directly-into-google-colab-c8f0f407d73a).  -->"
      ],
      "metadata": {
        "id": "K5NvKwkZIKOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSkHqQZV_S2Y",
        "outputId": "da430eb3-1761-43e5-baa9-1763a1442b5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We set the Kaggle configuration directory to be where the kaggle.json token is located."
      ],
      "metadata": {
        "id": "UbKVH6cTHdGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/gdrive/MyDrive/kaggle'"
      ],
      "metadata": {
        "id": "KPv9enSs_cqv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the movie reviews data (this requires installation of the kaggle package via `pip install kaggle`, if necessary).\n"
      ],
      "metadata": {
        "id": "6JgQP72HHlJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up6FxQUWAZAz",
        "outputId": "d3c7d70d-bab8-44eb-bc16-623964f628cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, copy the zip to the virtual machine and unzip it there.\n"
      ],
      "metadata": {
        "id": "CaE6m6OtHvti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/gdrive/MyDrive/kaggle/imdb-dataset-of-50k-movie-reviews.zip'\n",
        "!cp '{zip_path}' .\n",
        "!unzip -q 'imdb-dataset-of-50k-movie-reviews.zip'"
      ],
      "metadata": {
        "id": "3ESmJDY_BpO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7837f6-7c4c-4818-9e40-ed2c705f6666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the working directory to see that the necessary files are there.\n"
      ],
      "metadata": {
        "id": "ATlbs5xgH5Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqN_M0ZXF8IE",
        "outputId": "96cf99f0-8d16-40c9-a708-aa6c026b0036"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'IMDB Dataset.csv',\n",
              " 'imdb-dataset-of-50k-movie-reviews.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "To process the data, the first step is to read the data into a pandas dataframe."
      ],
      "metadata": {
        "id": "9d44PVprH9va"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QqJ2vkbqehwa"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"IMDB Dataset.csv\", lineterminator='\\n', converters={\"review\": str(), \"sentiment\": str()})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we split the data into train and test sets. Following the description on Kaggle, the split is 50/50.\n"
      ],
      "metadata": {
        "id": "c0kbsM8gxgGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(data)*0.5)\n",
        "test_size = len(data) - train_size"
      ],
      "metadata": {
        "id": "O9N5qYzTxe_I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle all the data (`fraction = 1`), and split the shuffled data into the train and test sets."
      ],
      "metadata": {
        "id": "VTpkmFhkx5Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_data = data.sample(frac=1)\n",
        "train_data, test_data = shuffled_data[:25000].copy(), shuffled_data[25000:].copy()\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8nBMM4LCx58l",
        "outputId": "f6acfc7f-3c88-4886-d5bd-9463910a456b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "2042   Olivier Assayas' film stars Asia Argento as a ...  negative\n",
              "8856   Surely the Gershwin family realizes this is on...  positive\n",
              "368    One of my favorite movies which has been overl...  positive\n",
              "9807   A Frank Capra WONDERS OF LIFE film.<br /><br /...  positive\n",
              "393    Goldeneye will always go down as one of thee m...  positive\n",
              "...                                                  ...       ...\n",
              "33298  I love All Dogs Go to Heaven even though I'm a...  positive\n",
              "29413  I rented this because I couldn't pass up the c...  negative\n",
              "21498  Boring and appallingly acted(Summer Pheonix). ...  negative\n",
              "26109  Needful Things was one of my favorite Stephen ...  negative\n",
              "43037  As a physicist, talk about blackholes and cosm...  negative\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96eb32dd-0d8c-47ae-8ece-2c96b72a310c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2042</th>\n",
              "      <td>Olivier Assayas' film stars Asia Argento as a ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8856</th>\n",
              "      <td>Surely the Gershwin family realizes this is on...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>One of my favorite movies which has been overl...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9807</th>\n",
              "      <td>A Frank Capra WONDERS OF LIFE film.&lt;br /&gt;&lt;br /...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>Goldeneye will always go down as one of thee m...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33298</th>\n",
              "      <td>I love All Dogs Go to Heaven even though I'm a...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29413</th>\n",
              "      <td>I rented this because I couldn't pass up the c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21498</th>\n",
              "      <td>Boring and appallingly acted(Summer Pheonix). ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26109</th>\n",
              "      <td>Needful Things was one of my favorite Stephen ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43037</th>\n",
              "      <td>As a physicist, talk about blackholes and cosm...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96eb32dd-0d8c-47ae-8ece-2c96b72a310c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96eb32dd-0d8c-47ae-8ece-2c96b72a310c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96eb32dd-0d8c-47ae-8ece-2c96b72a310c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6c6837d-1eb0-419f-9b1b-b9d296a25b27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6c6837d-1eb0-419f-9b1b-b9d296a25b27')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6c6837d-1eb0-419f-9b1b-b9d296a25b27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `VocabFromReviews` encapsulates the main prepocessing steps. The words in the training data reviews constitute the tokens in our vocabulary. We order them by frequency and form a dictionary between indices and tokens. The `VocabFromReviews` class includes the method `process_and_convert_review_to_tensor` which uses the vocabulary to tokenize, index, and pad any pandas Series of reviews; it outputs a pytorch tensor."
      ],
      "metadata": {
        "id": "KXq6OghrI2ru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X1AvXXx7ehwb"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "\n",
        "class VocabFromReviews:\n",
        "    \"\"\"\n",
        "    The Vocab takes a pd.Series of reviews, processes them into tokens by descending frequency, and creates dictionaries to move between tokens and indices\n",
        "    \"\"\"\n",
        "    def __init__(self, reviews: pd.Series, min_freq: int = 0):\n",
        "      tokenized_series = reviews.apply(\n",
        "          lambda review_text : [self.preprocess_string(word) for word in review_text.split()]\n",
        "      )\n",
        "      tokenized_list = tokenized_series.to_list()\n",
        "      tokens = list(itertools.chain.from_iterable(tokenized_list))\n",
        "      counts = Counter(tokens)\n",
        "      self.token_freqs = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "      self.idx_to_token = list(sorted(set(\n",
        "          ['<unk>'] + [token for token, freq in self.token_freqs if freq >= min_freq])))\n",
        "      self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
        "\n",
        "    def preprocess_string(self, s: str):\n",
        "      \"\"\" Keep only words, and make them lower case. Remove breaks.\"\"\"\n",
        "      s = re.sub(r\"[^\\w\\s]\", '', s).lower()\n",
        "      s = re.sub(r\"\\s+\", '', s)\n",
        "      s = re.sub(r\"\\d\", '', s)\n",
        "      if s == \"br\": return \"\"\n",
        "      return s\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.idx_to_token)\n",
        "\n",
        "    def convert_tokenized_review_to_indices(self, single_tokenized_review : list):\n",
        "      indices = []\n",
        "      for token in single_tokenized_review:\n",
        "          if token in self.token_to_idx and token:\n",
        "              indices.append(self.token_to_idx[token])\n",
        "      return indices\n",
        "\n",
        "\n",
        "    def process_and_convert_review_to_tensor(self, input_reviews: pd.Series):\n",
        "      \"\"\"\n",
        "      Take a pd.Series of reviews, tokenize, index according to the vocab dictionary, pad, and convert to a tensor\n",
        "      \"\"\"\n",
        "      indexed_series = input_reviews.apply(\n",
        "          lambda review_text :\n",
        "            self.convert_tokenized_review_to_indices(\n",
        "              [self.preprocess_string(word) for word in review_text.split()]\n",
        "          )\n",
        "      )\n",
        "      max_length = indexed_series.apply(lambda l : len(l)).max()\n",
        "      padded_indexed_series = indexed_series.apply(\n",
        "        lambda review_indices : [0]*(max_length- len(review_indices)) + review_indices\n",
        "      )\n",
        "      return torch.tensor(padded_indexed_series.values.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create the vocab from the training data."
      ],
      "metadata": {
        "id": "1Hf24ASQJOYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e_fph1XBehwc"
      },
      "outputs": [],
      "source": [
        "vocab = VocabFromReviews(train_data[\"review\"], min_freq=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the training data into padded indexed tokens."
      ],
      "metadata": {
        "id": "0tqGiwIrzQck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = vocab.process_and_convert_review_to_tensor(train_data[\"review\"])\n",
        "print(f\"size of train features = {train_features.size()}\")"
      ],
      "metadata": {
        "id": "aMOxAEIT0sa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the labels, encode a positive sentiment as 1 and a negative one as 0."
      ],
      "metadata": {
        "id": "XwZ_1uqRzZRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_pd = train_data[\"sentiment\"].apply(lambda s: int(s == \"positive\"))\n",
        "train_labels = torch.tensor(train_labels_pd.values.tolist()).unsqueeze(1).float()\n",
        "print(f\"size of train labels = {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "cEQs34wD4p2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7zQbHhehwd"
      },
      "source": [
        "\n",
        "## 3. Model\n",
        "\n",
        "We now define the recurrent neural network model. The model is many-to-one since we input a tokenized string but output only a single value (positive/negative). Hence, we use a hidden recurrent neural network that outputs a single value at the end, and this value is plugged into a fully connected neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjJe8O1vehwd"
      },
      "outputs": [],
      "source": [
        "class RNNHidden(nn.Module):\n",
        "    def __init__(self, num_layers, input_dim, embedding_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first = True)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text.size() = (batch size, length of sequence)\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        #embedded.size() = (batch_size, length of sequence)\n",
        "        _, hidden = self.lstm(embedded)\n",
        "\n",
        "        # Since this is a Many-to-One model, return only the last output\n",
        "        return hidden[-1][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 1\n",
        "HIDDEN_LAYERS = 2\n",
        "\n",
        "lstm_model = nn.Sequential(\n",
        "    RNNHidden(HIDDEN_LAYERS, INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM),\n",
        "    nn.Linear(HIDDEN_DIM, OUTPUT_DIM),\n",
        "    nn.Dropout(p=0.5)\n",
        ")\n",
        "print(lstm_model)"
      ],
      "metadata": {
        "id": "W5lCoTwtz3hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OZy2jmTehwe"
      },
      "source": [
        "## 4. Training\n",
        "\n",
        "Before training, we check is there is a GPU available. If so, the device will be the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF3cBjikehwe"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, define a binary accuracy function for evaluation."
      ],
      "metadata": {
        "id": "iahXPzFE0YW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie_4-Bp2ehwf"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We arrive at the training loop for the network."
      ],
      "metadata": {
        "id": "wblYR86rsMQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, num_epochs, verbose=False):\n",
        "\n",
        "    # Keep track of the loss and accuracy over the epochs\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "\n",
        "    model.train()\n",
        "    for i in tqdm.tqdm(range(num_epochs)):\n",
        "      for features, labels  in dataloader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(features)\n",
        "        loss = criterion(predictions, labels)\n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        train_acc.append(acc.item())\n",
        "\n",
        "      if verbose:\n",
        "        print(f\"Epoch {i+1}: loss = {round(train_loss[-1],4)}, accuracy = {round(train_acc[-1],4)}\")\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "TB1U59Muw2Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Dataset class for the review data. This is so that we can use the dataloader to create batches automatically."
      ],
      "metadata": {
        "id": "nldnVZFX02CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MovieReviewsDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "riVI-_X-0uSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the training dataset and the training dataloader."
      ],
      "metadata": {
        "id": "czeSc2U11AJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MovieReviewsDataset(train_features.to(device), train_labels.to(device))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "jSCHtFDB002B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a stochastic gradient descent optimzer. The loss function is the binary cross entropy combined with sigmoid."
      ],
      "metadata": {
        "id": "dXOqN8_Qs56A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVNmHGG2ehwf"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "lstm_model = lstm_model.to(device)\n",
        "optimizer = optim.SGD(lstm_model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We finally get to training the model!"
      ],
      "metadata": {
        "id": "yfvEgsJPtHwS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcjgJcwsehwg"
      },
      "outputs": [],
      "source": [
        "loss, acc = train(lstm_model, train_loader,\n",
        "    optimizer=optimizer, criterion=criterion, num_epochs=50, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now plot how the accuracy and loss change over the course of training."
      ],
      "metadata": {
        "id": "MKN9-iu_tKhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(acc)\n",
        "plt.xlabel(\"batch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"Plot of accuracy during training\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x1RW8HhLKkD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Plot of loss during training\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdEoSvbc9oCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "Finally, evaluate the model on the test set. We first have the evaluation function:"
      ],
      "metadata": {
        "id": "LF9i2k4-tPqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, features, labels, criterion, verbose=False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(features)\n",
        "        loss = criterion(predictions, labels)\n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "    if verbose:\n",
        "      print(f\"The test loss is {round(loss.item(), 4)}\")\n",
        "      print(f\"The test accuracy is {round(acc.item(), 4)}\")\n",
        "    return loss , acc"
      ],
      "metadata": {
        "id": "uT8yNhmsnM7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we obtain the test features and labels."
      ],
      "metadata": {
        "id": "SoV5QOQw2lXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = vocab.process_and_convert_review_to_tensor(test_data[\"review\"])\n",
        "print(f\"size of test features = {test_features.size()}\")\n",
        "\n",
        "test_labels_pd = test_data[\"sentiment\"].apply(lambda s: int(s == \"positive\"))\n",
        "test_labels = torch.tensor(test_labels_pd.values.tolist()).unsqueeze(1).float()\n",
        "print(f\"size of test labels = {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "otuh8nk_v6Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, evaluate the model on the test set. We need to do this with only part of the data"
      ],
      "metadata": {
        "id": "IoK5GiYV27rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "i = 0\n",
        "while i+500 < len(test_features):\n",
        "  test_loss, test_acc = evaluate(\n",
        "    model= lstm_model,\n",
        "    features= test_features[i:i+500].to(device),\n",
        "    labels = test_labels[i:i+500].to(device),\n",
        "    criterion=criterion,\n",
        "    verbose = False\n",
        "  )\n",
        "  test_loss_list.append(test_loss.item())\n",
        "  test_acc_list.append(test_acc.item())\n",
        "  i += 500\n",
        "\n",
        "mean_loss = sum(test_loss_list)/ len(test_loss_list)\n",
        "mean_acc = sum(test_acc_list)/ len(test_acc_list)\n",
        "\n",
        "print(f\"The test loss is {round(mean_loss, 4)}\")\n",
        "print(f\"The test accuracy is {round(mean_acc, 4)}\")\n"
      ],
      "metadata": {
        "id": "hASdF855EmDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWnLl8Xt13gj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}